1.Linear Regression :  Linear Regression ek supervised ML algorithm hai jo continuous output predict karta hai â€” jaise house price, sales, salary, temperature etc.
2: Cost Function â€“ MSE (Mean Squared Error) : Cost function woh hota hai jo batata hai ki model ki prediction kitni galat j aa sahi hai.  MSE = Mean Squared Error : MSE = (1/n) * Î£ (y_pred - y_actual)Â²
3.Gradient Descent (Very Important ðŸŒŸ) : Gradient Descent ek optimization algorithm hai jo MSE ko minimize karta hai. : Î¸ = Î¸ - Î± * âˆ‚(Cost)/âˆ‚Î¸
                                          Socho ek pahad (mountain) hai, aur aap bottom par jana chahte ho: 
                                          Har step me slope check karte ho
                                          Slope jahan steep ho, wahaan bada step
                                          Jahan flat ho, chota step

4.Normal Equation : Normal Equation ek direct formula hai jisse bina gradient descent ke exact best weights nikal jaate hain. Î¸ = (Xáµ€X)â»Â¹Xáµ€y
5.Multicollinearity (Glassdoor Verified) : Multicollinearity = jab 2 ya zyada features ek dusre se heavily correlated ho.

                                            For example:
                                            
                                            Area in square feet
                                            
                                            Area in square meters
                                            
                                            Dono same cheez bol rahe = multicollinearity.


Variance Inflation Factor (VIF) : VIF identifies multicollinearity.

                                            Formula:
                                            VIF = 1 / (1 - RÂ²)                                          
                                            Rules:
                                            VIF > 5 â†’ moderate multicollinearity

VIF > 10 â†’ severe multicollinearity
